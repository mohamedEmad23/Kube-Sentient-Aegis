# AEGIS Environment Configuration
# Copy this file to .env and fill in your values
#
# All AEGIS settings use the AEGIS_ prefix
# See src/aegis/config/settings.py for all available options

# ===========================================================================
# Core Settings
# ===========================================================================

# Environment: development, staging, production
AEGIS_ENVIRONMENT=development

# Shadow mode (dry-run) - HIGHLY RECOMMENDED to keep enabled initially
AEGIS_SHADOW_MODE_ENABLED=true

# Auto remediation - Only enable after thorough testing with shadow mode
AEGIS_AUTO_REMEDIATION_ENABLED=false

# ===========================================================================
# LLM Provider Configuration
# ===========================================================================

# Provider: ollama, groq, gemini, openai, together
AEGIS_LLM_PROVIDER=ollama

# LLM Temperature (0.0-2.0, lower = more deterministic)
AEGIS_LLM_TEMPERATURE=0.1

# Maximum tokens in response
AEGIS_LLM_MAX_TOKENS=4096

# ===========================================================================
# Ollama Configuration (for local GPU inference)
# ===========================================================================

# Ollama server endpoint
AEGIS_LLM_OLLAMA_HOST=http://localhost:11434

# Ollama model to use (run 'make gpu-check' for recommendations)
AEGIS_LLM_OLLAMA_MODEL=llama3.2:3b

# ===========================================================================
# Cloud LLM API Keys (for cloud inference)
# ===========================================================================

# Groq (RECOMMENDED - Free tier, fastest inference)
# Get your key at: https://console.groq.com/
AEGIS_LLM_GROQ_API_KEY=

# Google Gemini (RECOMMENDED - Free tier, large context)
# Get your key at: https://aistudio.google.com/apikey
AEGIS_LLM_GEMINI_API_KEY=

# OpenAI (Optional - Industry standard, paid)
# Get your key at: https://platform.openai.com/api-keys
AEGIS_LLM_OPENAI_API_KEY=

# Together AI (Optional - Open source models)
# Get your key at: https://api.together.xyz/
AEGIS_LLM_TOGETHER_API_KEY=

# ===========================================================================
# Kubernetes Configuration
# ===========================================================================

# Running inside cluster (auto-detected in most cases)
AEGIS_K8S_IN_CLUSTER=false

# Kubeconfig path (leave empty to use default ~/.kube/config)
AEGIS_K8S_KUBECONFIG=

# Kubernetes context (leave empty for current context)
AEGIS_K8S_CONTEXT=

# Namespace to watch (leave empty for all namespaces)
AEGIS_K8S_NAMESPACE=

# ===========================================================================
# Observability
# ===========================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
AEGIS_OBSERVABILITY_LOG_LEVEL=INFO

# Log format: json (production) or console (development)
AEGIS_OBSERVABILITY_LOG_FORMAT=console

# Enable Prometheus metrics endpoint
AEGIS_OBSERVABILITY_METRICS_ENABLED=true

# Metrics port
AEGIS_OBSERVABILITY_METRICS_PORT=8080

# Enable OpenTelemetry tracing
AEGIS_OBSERVABILITY_TRACING_ENABLED=false

# OTLP collector endpoint (if tracing enabled)
AEGIS_OBSERVABILITY_OTLP_ENDPOINT=http://localhost:4317

# ===========================================================================
# Shadow Mode Configuration
# ===========================================================================

# Enable shadow mode for all actions
AEGIS_SHADOW_ENABLED=true

# Require human verification before executing actions
AEGIS_SHADOW_VERIFICATION_REQUIRED=true

# Minimum confidence to auto-approve actions (0.0-1.0)
AEGIS_SHADOW_CONFIDENCE_THRESHOLD=0.85

# Maximum auto-approved actions per hour
AEGIS_SHADOW_MAX_AUTO_ACTIONS_PER_HOUR=10

# ===========================================================================
# Team Setup Examples
# ===========================================================================

# Example 1: Developer with NVIDIA GPU (6GB+ VRAM)
# AEGIS_LLM_PROVIDER=ollama
# AEGIS_LLM_OLLAMA_HOST=http://localhost:11434
# AEGIS_LLM_OLLAMA_MODEL=llama3.2:3b

# Example 2: Developer with Intel Iris Xe (cloud APIs only)
# AEGIS_LLM_PROVIDER=groq
# AEGIS_LLM_GROQ_API_KEY=your_groq_key

# Example 3: CI/CD pipeline
# AEGIS_LLM_PROVIDER=groq
# AEGIS_LLM_GROQ_API_KEY=your_groq_key
# AEGIS_SHADOW_ENABLED=true
